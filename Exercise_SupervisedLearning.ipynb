{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0efa7e0-31c2-4848-ae3e-39fdd86ab3df",
   "metadata": {},
   "source": [
    "Try classifying the digits dataset with nearest neighbors and a linear model. Leave out the last 10% and test prediction performance on these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a59dd33c-b1f7-499b-8762-6ca76d023e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, neighbors, linear_model\n",
    "\n",
    "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "X_digits = X_digits / X_digits.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61cb71d5-954e-448e-9f9d-2a2d62186bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples = len(X_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa838446-07e4-4512-8a68-c1c2706e9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The [:rand_num] syntax leaves out certain items of the array/dataset provided\n",
    "# The training uses [:rand_num]\n",
    "# The test uses [rand_num :]\n",
    "\n",
    "# Why use int?\n",
    "X_train = X_digits[:int(.9 * nSamples)]\n",
    "y_train = y_digits[:int(.9 * nSamples)]\n",
    "\n",
    "X_test = X_digits[int(.9 * nSamples) :]\n",
    "y_test = y_digits[int(.9 * nSamples) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851baaa6-685a-47b6-96d0-bda9564af759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn stands for 'k nearest neighbors'\n",
    "# scikit-learn implements two different nearest neighbors classifiers: KNeighborsClassifier implements learning based on the \n",
    "# k nearest neighbors of each query point, where  is an integer value specified by the user.\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# LinearRegression, in its simplest form, fits a linear model to the data set by adjusting a set of parameters in order to make\n",
    "# the sum of the squared residuals of the model as small as possible.\n",
    "\n",
    "logistic = linear_model.LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ecc731b-5d4a-415c-8201-6d4e31ffd500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 0.961111\n",
      "LogisticRegression score: 0.933333\n"
     ]
    }
   ],
   "source": [
    "# Print out results: %f inserts the following results after it\n",
    "# Using 'fit', we fit an estimator to be able to predict the classes to which unseen samples belong. EX. fit(X, y)\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "# and 0 means that there is no linear relationship\n",
    "# between X and y.\n",
    "\n",
    "# We fit and print the data of 'knn' (Classifier) and 'logistic' (linear model for logistic regression) \n",
    "# into the training model and have it score between the test models\n",
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))\n",
    "print('LogisticRegression score: %f'\n",
    "      % logistic.fit(X_train, y_train).score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf226c8-1cbe-43b1-acc3-73a0d57100a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
